{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-73' coro=<Server.serve() done, defined at c:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\uvicorn\\server.py:67> exception=KeyboardInterrupt()>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\uvicorn\\main.py\", line 577, in run\n",
      "    server.run()\n",
      "  File \"c:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\uvicorn\\server.py\", line 65, in run\n",
      "    return asyncio.run(self.serve(sockets=sockets))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\muham\\AppData\\Roaming\\Python\\Python312\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\muham\\AppData\\Roaming\\Python\\Python312\\site-packages\\nest_asyncio.py\", line 92, in run_until_complete\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\muham\\AppData\\Roaming\\Python\\Python312\\site-packages\\nest_asyncio.py\", line 133, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py\", line 396, in __wakeup\n",
      "    self.__step()\n",
      "  File \"c:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py\", line 303, in __step\n",
      "    self.__step_run_and_handle_result(exc)\n",
      "  File \"c:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\uvicorn\\server.py\", line 68, in serve\n",
      "    with self.capture_signals():\n",
      "  File \"c:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py\", line 144, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"c:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\uvicorn\\server.py\", line 328, in capture_signals\n",
      "    signal.raise_signal(captured_signal)\n",
      "KeyboardInterrupt\n",
      "INFO:     Started server process [16208]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:5051 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:51985 - \"POST /predict/ HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "import uvicorn\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel, Field\n",
    "import torch\n",
    "from transformers import BertTokenizerFast, BertForTokenClassification, BertForSequenceClassification\n",
    "import nest_asyncio\n",
    "import os\n",
    "import spacy\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "class Item(BaseModel):\n",
    "    text: str = Field(..., example=\"\"\"Fiber 100mb SuperOnline kullanıcısıyım yaklaşık 2 haftadır @Twitch @Kick_Turkey gibi canlı yayın platformlarında 360p yayın izlerken donmalar yaşıyoruz. Başka hiç bir operatörler bu sorunu yaşamazken ben parasını verip alamadığım hizmeti neden ödeyeyim ? @Turkcell \"\"\")\n",
    "\n",
    "# Dosya yollarını kontrol etme\n",
    "ner_model_path = \"fine-tuned-bert-ner-optimized\"\n",
    "sentiment_model_path = \"entity_sentiment_model\"\n",
    "sentiment_tokenizer_path = \"entity_sentiment_tokenizer\"\n",
    "\n",
    "if not os.path.exists(ner_model_path):\n",
    "    raise FileNotFoundError(f\"NER modeli dizini bulunamadı: {ner_model_path}\")\n",
    "if not os.path.exists(sentiment_model_path):\n",
    "    raise FileNotFoundError(f\"Sentiment modeli dizini bulunamadı: {sentiment_model_path}\")\n",
    "if not os.path.exists(sentiment_tokenizer_path):\n",
    "    raise FileNotFoundError(f\"Sentiment tokenizer dizini bulunamadı: {sentiment_tokenizer_path}\")\n",
    "\n",
    "# NER modelini yükleme\n",
    "tokenizer_ner = BertTokenizerFast.from_pretrained(ner_model_path)\n",
    "model_ner = BertForTokenClassification.from_pretrained(ner_model_path)\n",
    "model_ner.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "# Sentiment modelini yükleme\n",
    "tokenizer_sentiment = BertTokenizerFast.from_pretrained(sentiment_tokenizer_path)\n",
    "model_sentiment = BertForSequenceClassification.from_pretrained(sentiment_model_path)\n",
    "model_sentiment.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "# Etiketler\n",
    "id_to_label_ner = {0: \"O\", 1: \"B-ORG\", 2: \"I-ORG\"}\n",
    "id_to_label_sentiment = {0: \"notr\", 1: \"olumlu\", 2: \"olumsuz\"}\n",
    "\n",
    "# Spacy modeli yükleme\n",
    "nlp = spacy.blank(\"tr\")\n",
    "nlp.add_pipe('sentencizer')\n",
    "\n",
    "def extract_entities(text):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    inputs = tokenizer_ner(text.lower(), truncation=True, padding='max_length', max_length=512, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    model_ner.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model_ner(**inputs)\n",
    "        predictions = torch.argmax(outputs.logits, dim=2)\n",
    "    tokens = tokenizer_ner.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "    predicted_labels = [id_to_label_ner[pred.item()] for pred in predictions[0]]\n",
    "    entities = []\n",
    "    current_entity = []\n",
    "    for token, label in zip(tokens, predicted_labels):\n",
    "        if token.startswith(\"##\"):\n",
    "            if current_entity:\n",
    "                current_entity[-1] += token[2:]\n",
    "        else:\n",
    "            if label.startswith(\"B-\"):\n",
    "                if current_entity:\n",
    "                    entities.append(\" \".join(current_entity))\n",
    "                    current_entity = []\n",
    "                if token != \"[PAD]\":\n",
    "                    current_entity.append(token)\n",
    "            elif label.startswith(\"I-\") and current_entity:\n",
    "                if token != \"[PAD]\":\n",
    "                    current_entity.append(token)\n",
    "            else:\n",
    "                if current_entity:\n",
    "                    entities.append(\" \".join(current_entity))\n",
    "                    current_entity = []\n",
    "    if current_entity:\n",
    "        entities.append(\" \".join(current_entity))\n",
    "    entities = [entity for entity in entities if entity.strip() and entity.lower() != '[pad]']\n",
    "    \n",
    "    # Orijinal metindeki entity'leri bulma\n",
    "    original_entities = []\n",
    "    for entity in entities:\n",
    "        start_idx = text.lower().find(entity.lower())\n",
    "        end_idx = start_idx + len(entity)\n",
    "        original_entity = text[start_idx:end_idx]\n",
    "        original_entities.append(original_entity)\n",
    "    \n",
    "    return original_entities\n",
    "\n",
    "def split_sentences(text, entities):\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text.strip() for sent in doc.sents]\n",
    "    entity_sentences = {entity: [] for entity in entities}\n",
    "    for sentence in sentences:\n",
    "        for entity in entities:\n",
    "            if entity.lower() in sentence.lower():\n",
    "                entity_sentences[entity].append(sentence)\n",
    "    return entity_sentences\n",
    "\n",
    "def analyze_sentiment(text, entities):\n",
    "    results = []\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    entity_sentences = split_sentences(text, entities)\n",
    "    for entity, sentences in entity_sentences.items():\n",
    "        combined_sentence = \" \".join(sentences)\n",
    "        inputs = tokenizer_sentiment(combined_sentence, truncation=True, padding='max_length', max_length=512, return_tensors=\"pt\")\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        model_sentiment.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model_sentiment(**inputs)\n",
    "            predictions = torch.argmax(outputs.logits, dim=1)\n",
    "        predicted_sentiment = id_to_label_sentiment[predictions.item()]\n",
    "        results.append({\"entity\": entity, \"sentiment\": predicted_sentiment})\n",
    "    return results\n",
    "\n",
    "@app.post(\"/predict/\", response_model=dict)\n",
    "async def predict(item: Item):\n",
    "    text = item.text\n",
    "    entities = extract_entities(text)\n",
    "    sentiment_results = analyze_sentiment(text, entities)\n",
    "    result = {\n",
    "        \"entity_list\": entities,\n",
    "        \"results\": sentiment_results\n",
    "    }\n",
    "    return result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=7552)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
